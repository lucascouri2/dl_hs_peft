{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f5c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580febf",
   "metadata": {},
   "source": [
    "## Dataset em ingles apenas para testes iniciais de funcionamento do código\n",
    "https://github.com/paul-rottger/hatecheck-data/blob/main/all_cases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocess(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # basic normalizations used in the original pipeline\n",
    "    text = text.replace('&amp;', ' and ')\n",
    "    text = text.replace('&', ' and ')\n",
    "    text = re.sub(r'[\\r\\n]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def load_synthetic(path: str, text_col: str = 'text', label_col: str = 'label') -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = pd.read_csv(\"data/all_cases.csv\") \n",
    "    \n",
    "    df['text'] = df['test_case']\n",
    "    df[\"label\"] = df[\"label_gold\"].apply(lambda x: 1 if x == \"hateful\" else 0)\n",
    "\n",
    "    df = df[[text_col, label_col]].dropna().reset_index(drop=True)\n",
    "    df = df.rename(columns={text_col: 'text', label_col: 'label'})\n",
    "    df['text'] = df['text'].astype(str).map(simple_preprocess)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size = 0.25, random_state=42, shuffle=True)\n",
    "    df_train, df_val = train_test_split(df_train, test_size = 0.20, random_state=42, shuffle=True)\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "train_df, val_df, test_df = load_synthetic(path=\"data/all_cases.csv\")\n",
    "\n",
    "train_df.to_csv(\"data/1en_train.csv\") #60%\n",
    "val_df.to_csv(\"data/1en_val.csv\") #15%\n",
    "test_df.to_csv(\"data/1en_test.csv\") #25%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73981a9",
   "metadata": {},
   "source": [
    "## Datasets em português (splits individuais)\n",
    "- OLID-BR: https://huggingface.co/datasets/dougtrajano/olid-br\n",
    "- hateBR: https://github.com/franciellevargas/HateBR/blob/main/dataset/HateBR.csv\n",
    "\n",
    "Vou fazer o split em train, val e test pra deixar pronto pros experimentos (usando um único dataset por vez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11146fd6",
   "metadata": {},
   "source": [
    "#### 1. Olid-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5bb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dougtrajano/olid-br\")\n",
    "\n",
    "df_train = dataset[\"train\"].to_pandas()\n",
    "df_test = dataset[\"test\"].to_pandas()\n",
    "\n",
    "df_train[\"label\"] = df_train[\"is_offensive\"].apply(lambda x: 1 if x == \"OFF\" else 0)\n",
    "df_test[\"label\"] = df_test[\"is_offensive\"].apply(lambda x: 1 if x == \"OFF\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c1c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar todo o dataset olidbr em um csv só\n",
    "\n",
    "combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "combined_df.to_csv(\"data/olidbr/full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef30d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitar df_train em train (60%) e val (15%)\n",
    "# Como df_train representa 75% do total, queremos que a validação seja:\n",
    "# val_ratio = (15% total) / (75% total após split inicial)\n",
    "\n",
    "val_ratio = 0.15 / 0.75   # = 0.20\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train,\n",
    "    test_size=val_ratio,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "df_train.to_csv(\"data/olidbr/train.csv\", index=False) #60%\n",
    "df_val.to_csv(\"data/olidbr/val.csv\", index=False) #15%\n",
    "df_test.to_csv(\"data/olidbr/test.csv\", index=False) #25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919e02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(combined_df)==(len(df_train)+len(df_test)+len(df_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b3118",
   "metadata": {},
   "source": [
    "#### 2. HateBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4127ccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anotator1</th>\n",
       "      <th>anotator2</th>\n",
       "      <th>anotator3</th>\n",
       "      <th>label</th>\n",
       "      <th>links_post</th>\n",
       "      <th>account_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mais um lixo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Essa nao tem vergonha na cara!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Essa mulher é doente.pilantra!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comunista safada...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  anotator1  \\\n",
       "0   1                                       Mais um lixo          1   \n",
       "1   2                    Essa nao tem vergonha na cara!!          1   \n",
       "2   3                     Essa mulher é doente.pilantra!          1   \n",
       "3   4                                Comunista safada...          1   \n",
       "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...          1   \n",
       "\n",
       "   anotator2  anotator3  label                                links_post  \\\n",
       "0          1          1      1  https://www.instagram.com/p/B2uThqdH9xI/   \n",
       "1          1          1      1  https://www.instagram.com/p/B2uThqdH9xI/   \n",
       "2          1          1      1  https://www.instagram.com/p/B2uThqdH9xI/   \n",
       "3          1          1      1  https://www.instagram.com/p/B2uThqdH9xI/   \n",
       "4          1          1      1  https://www.instagram.com/p/B2uThqdH9xI/   \n",
       "\n",
       "     account_post  \n",
       "0  Carla Zambelli  \n",
       "1  Carla Zambelli  \n",
       "2  Carla Zambelli  \n",
       "3  Carla Zambelli  \n",
       "4  Carla Zambelli  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatebr = pd.read_csv(\"data/hatebr/full.csv\")\n",
    "hatebr = hatebr.rename(columns={\n",
    "    \"comentario\": \"text\",\n",
    "    \"label_final\": \"label\"\n",
    "})\n",
    "hatebr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26499bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatebr_train, hatebr_test = train_test_split(hatebr, test_size = 0.25, random_state=42, shuffle=True)\n",
    "hatebr_train, hatebr_val = train_test_split(hatebr_train, test_size = 0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f712b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(hatebr)==(len(hatebr_train)+len(hatebr_test)+len(hatebr_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc863116",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatebr_train.to_csv(\"data/hatebr/train.csv\", index=False) #60%\n",
    "hatebr_val.to_csv(\"data/hatebr/val.csv\", index=False) #15%\n",
    "hatebr_test.to_csv(\"data/hatebr/test.csv\", index=False) #25%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89a749",
   "metadata": {},
   "source": [
    "## Cross-dataset\n",
    "- OLID-BR: https://huggingface.co/datasets/dougtrajano/olid-br\n",
    "- hateBR: https://github.com/franciellevargas/HateBR/blob/main/dataset/HateBR.csv\n",
    "\n",
    "A ideia aqui é usar um dataset para train+val e o outro inteiro para test. \n",
    "Vou avaliar os 2 casos: \n",
    "- treinar em olidbr e testar em hatebr (vou splitar o olidbr em train e val, e usar o hatebr completo como test)\n",
    "- treinar em hatebr e avaliar em olidbr (vou splitar o hatebr em train e val, e usar o olidbr completo como test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be29140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl_projeto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
